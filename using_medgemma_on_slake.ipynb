{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MedGemma as Remotely Sourced Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading config file fiftyone.yml from Voxel51/SLAKE\n",
      "Loading dataset\n",
      "Importing samples...\n",
      " 100% |███████████████████| 50/50 [4.5ms elapsed, 0s remaining, 11.1K samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "dataset = load_from_hub(\n",
    "    \"Voxel51/SLAKE\",\n",
    "    name=\"SLAKE\",\n",
    "    overwrite=True,\n",
    "    max_samples=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/medgemma\", overwrite=True)\n",
    "\n",
    "foz.download_zoo_model(\n",
    "    \"https://github.com/harpreetsahota204/medgemma\",\n",
    "    model_name=\"google/medgemma-4b-it\", \n",
    ")\n",
    "\n",
    "model = foz.load_zoo_model(\n",
    "    \"google/medgemma-4b-it\",\n",
    "    quantized=True,\n",
    "    # install_requirements=True #run this to install requirements if they're not already\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use MedGemma for Classification\n",
    "\n",
    "You can use this model for a zero-shot classification task as follows, which will add a [FiftyOne Classificaton](https://docs.voxel51.com/api/fiftyone.core.labels.html#fiftyone.core.labels.Classification) to your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_system_labels = dataset.distinct(\"modality.label\")\n",
    "\n",
    "model.operation = \"classify\"\n",
    "\n",
    "model.prompt = \"As a medical expert your task is to classify this image into exactly one of the following types: \" + \", \".join(body_system_labels)\n",
    "\n",
    "dataset.apply_model(model, label_field=\"pred_modality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Classification: {\n",
       "    'id': '6830a40a7a3316c437168c05',\n",
       "    'tags': [],\n",
       "    'label': 'X-Ray',\n",
       "    'confidence': None,\n",
       "    'logits': None,\n",
       "}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['modality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the model prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Classification: {\n",
       "     'id': '6830d550d69a8c1f151f7b90',\n",
       "     'tags': [],\n",
       "     'label': 'X-Ray',\n",
       "     'confidence': None,\n",
       "     'logits': None,\n",
       " }>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['pred_modality.classifications']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MedGemma for VQA\n",
    "\n",
    "You can use the model for visual question answering as shown below. This example will use the same prompt on each [Sample](https://docs.voxel51.com/api/fiftyone.core.sample.html#module-fiftyone.core.sample) in the Dataset. Note the default system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert radiologist, histopathologist, ophthalmologist, and dermatologist.\n",
      "\n",
      "Your expert opinion is needed for in classifiying medical images. A given image may have multiple relevant classifications.  \n",
      "\n",
      "You may be requested to select from a list of classifications, or asked to leverage your expertise medical for a diagnosis.\n",
      "\n",
      "In any event, report your classifications as JSON array in this format: \n",
      "\n",
      "```json\n",
      "{\n",
      "    \"classifications\": [\n",
      "        {\n",
      "            \"label\": \"descriptive medical condition or relevant label\",\n",
      "            \"label\": \"descriptive medical condition or relevant label\",\n",
      "            ...,\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "Always return your response as valid JSON wrapped in ```json blocks.  You may produce multiple lables if they are relevant or if you are asked to. Do not report your confidence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can customize the system prompt as follows to guide the model's response. Note that we are using an existing field on the sample by passing `prompt_field=\"question\"` into the [`apply_model`](https://docs.voxel51.com/api/fiftyone.core.dataset.html) method of the [Dataset](https://docs.voxel51.com/api/fiftyone.core.dataset.html).\n",
    "\n",
    "Note that if you want to parse the model output as a [FiftyOne Classification](https://docs.voxel51.com/api/fiftyone.core.labels.html#fiftyone.core.labels.Classification) then you need to very specifically prompt the model to output in a way that this integration expects, that is:\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classifications\": [\n",
    "        {\n",
    "            \"label\": \"your answer to the question\",\n",
    "            ...,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Notice below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"classify\"\n",
    "\n",
    "model.system_prompt = \"\"\"You have expert-level medical knowledge in radiology, histopathology, ophthalmology, and dermatology.\n",
    "\n",
    "You will be asked a question and are required to provide your answer. Your answer must be in the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"classifications\": [\n",
    "        {\n",
    "            \"label\": \"your answer to the question\",\n",
    "            ...,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Always return your response as valid JSON wrapped in ```json blocks and respond only with one answer.\n",
    "\"\"\"\n",
    "\n",
    "dataset.apply_model(\n",
    "    model, \n",
    "    label_field=\"pred_answer_6\", \n",
    "    prompt_field=\"question_6\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which organ is abnormal, heart or lung?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['question_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Classification: {\n",
       "    'id': '6830a40a7a3316c437168c0e',\n",
       "    'tags': [],\n",
       "    'label': 'Heart',\n",
       "    'confidence': None,\n",
       "    'logits': None,\n",
       "}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['answer_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Classification: {\n",
       "     'id': '6830d5a0d69a8c1f151f7bc2',\n",
       "     'tags': [],\n",
       "     'label': 'Heart',\n",
       "     'confidence': None,\n",
       "     'logits': None,\n",
       " }>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.first()['pred_answer_6.classifications']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For open-ended generation, you can use `vqa` mode. Note that with both modes you can use a single question on each sample as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.system_prompt = None # we need to clear the custom system prompt  \n",
    "\n",
    "model.operation=\"vqa\"\n",
    "\n",
    "model.prompt = \"Describe any anomolies in this the image that you observe.\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"open_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I will analyze the chest X-ray provided.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "*   **Cardiomegaly:** The heart appears enlarged (cardiomegaly). This is evident by the increased prominence of the cardiac silhouette, particularly the left ventricle.\n",
      "*   **Mediastinal Devices:** There are multiple devices visible within the mediastinum, including a pacemaker/ICD device. The leads appear to be in standard positions.\n",
      "*   **Pulmonary Vascularity:** The pulmonary vasculature appears relatively normal in terms of distribution and prominence.\n",
      "*   **Lung Fields:** The lung fields appear clear with no obvious consolidation, effusions, or masses.\n",
      "*   **Bones:** The bony structures of the ribs and sternum appear intact.\n",
      "*   **Mediastinal Width:** The mediastinal width appears to be within normal limits.\n",
      "\n",
      "**Potential Anomalies/Considerations:**\n",
      "\n",
      "*   **Cardiomegaly:** The cardiomegaly could be due to various factors, including hypertension, valvular heart disease, cardiomyopathy, or congenital heart defects. Further evaluation with echocardiography is needed to determine the underlying cause.\n",
      "*   **Device Placement:** The pacemaker/ICD device appears to be in standard position. However, the specific type of device and the presence of any complications (e.g., lead dislodgement, infection) would require further evaluation.\n",
      "\n",
      "**Disclaimer:** This is a preliminary interpretation based on a single chest X-ray. A definitive diagnosis requires a comprehensive clinical evaluation, including patient history, physical examination, and potentially additional imaging studies (e.g., echocardiography, CT scan).\n",
      "\n",
      "**In summary, the chest X-ray shows cardiomegaly and the presence of mediastinal devices. Further evaluation is needed to determine the underlying cause of the cardiomegaly and to assess the status of the mediastinal devices.**\n",
      "\n",
      "**Important Note:** This analysis is for informational purposes only and should not be considered a substitute for professional medical advice.\n"
     ]
    }
   ],
   "source": [
    "print(dataset.first()[\"open_response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use you can use a Sample field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0% ||------------------|  0/50 [3.2ms elapsed, ? remaining, ? samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2% |/------------------|  1/50 [6.7s elapsed, 5.5m remaining, 0.1 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4% |-------------------|  2/50 [8.7s elapsed, 3.5m remaining, 0.2 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6% |█\\-----------------|  3/50 [10.7s elapsed, 2.8m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8% |█|-----------------|  4/50 [12.0s elapsed, 2.3m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10% |█/-----------------|  5/50 [17.5s elapsed, 2.6m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12% |██-----------------|  6/50 [19.2s elapsed, 2.3m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  14% |██\\----------------|  7/50 [20.7s elapsed, 2.1m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16% |███|---------------|  8/50 [23.3s elapsed, 2.0m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18% |███/---------------|  9/50 [32.6s elapsed, 2.5m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20% |███----------------| 10/50 [33.9s elapsed, 2.2m remaining, 0.3 samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "model.operation=\"vqa\"\n",
    "\n",
    "dataset.apply_model(\n",
    "    model, \n",
    "    label_field=\"answer_5_vqa\", \n",
    "    prompt_field=\"question_5\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()[\"question_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()[\"answer_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()[\"answer_5_vqa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "\n",
    "You can use FiftyOne's [Evaluation API](https://docs.voxel51.com/user_guide/evaluation.html) to evaluate model performance via the SDK. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dataset.evaluate_classifications(\n",
    "    \"pred_modality\",\n",
    "    gt_field=\"modality\",\n",
    "    eval_key=\"eval_simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then review as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = results.plot_confusion_matrix()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can, of course, do all of this in the App as shown here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fo_develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
